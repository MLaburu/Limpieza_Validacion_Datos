---
title: 'Práctica 2: Limpieza y validación de los datos'
author: "Autores: Mikel Laburu Haro, Unai Mateos Corral"
date: "Curso 2018/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: paper
    toc: yes
    toc_depth: 3
    includes:
      in_header: Cabecera.html
lang: es
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

# Introducción
## Descripción

En esta actividad se lleva a cabo el tratamiento del dataset "Fifa 18 More Complete Player Dataset" extraido de Kaggle (https://www.kaggle.com/kevinmh/fifa-18-more-complete-player-dataset/home), con el que se elabora un caso práctico en el que se emplean herramientas de integración, limpieza, validación y análisis.

## Objetivos
Los objetivos que se pretenden lograr mediante la elaboración de esta actividad son los siguientes:

  * Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
  * Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
  * Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
  * Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
  * Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
  * Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
  * Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Competencias
Desarrollando a su vez las siguientes competencias del máster de Ciencia de Datos:

  * Capacidad de analizar un problema en el nivel de abstraccn adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
  * Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.

# Dataset

## Descripción del dataset

A continuación se realiza la carga del conjuto de datos al completo, y posteriormente se hace la selección de los atributos que se consideran de mayor relevancia, llegando a simplificar el datataset considerablemente, reduciendo el número de columnas de 185 a 46. Además, a modo de ejemplo, se muestra el valor de cinco atributos de las diez primeras instancias.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Cargamos el Dataset
myData <- read.csv("FIFA.csv", header = TRUE, sep = ",")
# Seleccion de los atributos a utilizar
myDataAux <- myData[,c("name","club","age","height_cm","weight_kg","nationality","eur_value", "eur_wage", "eur_release_clause",
                       "overall","potential","pac","sho","pas","dri","def","phy","crossing","finishing","heading_accuracy", "short_passing",
                       "volleys","dribbling","curve","free_kick_accuracy","long_passing","ball_control","acceleration","sprint_speed",
                       "agility", "reactions", "balance", "shot_power", "jumping", "stamina", "strength", "long_shots", "aggression",
                       "interceptions","positioning","vision","penalties","composure","marking","standing_tackle","sliding_tackle")]

# Mostrar las primeras 10 lineas del dataset y el contenido de 5 variables
head(myDataAux[,1:5],10)
# Tipo de los datos de cada variable
sapply(myDataAux,class)
```
Este conjunto de datos consta de un total de 17994 registros de jugadores, y como ya se ha comentado, cada una de ellos queda finalmente caracterizado por 46 atributos, entre los que se puede observar su nombre, su salarioo sus habilidades. A continuación se realiza una breve descripción de alguno de estos atributos:

  * **Name**: Nombre completo del jugador.
  * **Club**: Equipo al que pertenece el jugador.
  * **Age**: Edad del jugador.
  * **Eur_value**: Valor en euros que el juego estima para el jugador.
  * **Eur_wage**: Salario en euros del jugador.
  * **Eur_release_clause**: Cláusula de rescisión del jugador.
  * **Overall**: Puntuación media del jugador.
  * **PAC**: (Ritmo) Atributo que representa la media de los atributos de veloricadad (aceleración, velocidad...).
  * **Sho**: (Disparo) Atributo que representa la media de los atributos de disparo (finalización, remate de cabeza...).
  * **Pas**: (Pase) Atributo que representa la media de los atributos de pase (pase en corto, pase en largo...).
  * **Dri**: (Regate) Atributo que representa la media de los atributos de regate (control del balón, dribring...).
  * **Def**: (Defensa) Atributo que representa la media de los atributos defensivos (anticipación, entrada...).
  * **Phy**: (Físico) Atributo que representa la media de los atributos físicos (resistencia, fuerza...).


# Limpieza de los datos
## Eliminación de ceros, vacios y nulos
En este apartado se pretende limpiar el conjunto de datos de tal forma que no disponga ni de ceros, ni de valores vacíos, ni de valores nulos.

En primer lugar se realizará el tratamiento de valores nulos, como se aprecia a continuación el conjunto de datos dispone de valores nulos en los campos de la columna "eur_release_clause". Para no disponer de estos valores existen distintas estrategias como eliminar los registros en los que aparece este valor o asignar la media de "eur_release_clause" a estos campos, pero en este caso se ha considerado más oportuno la imputación de valores basada en $k$ vecinos más próximos, o más comúnmente conocida como $kNN-imputation$, debido principalmente a que los registros de este conjunto de datos guardan relación entre sí.
```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
library(VIM)

colSums(is.na(myDataAux))

# Tratamiento de valores nulos
myDataAux$eur_release_clause <- kNN(myDataAux)$eur_release_clause

```

Tras comprobar que no quedan valores nulos, es momento de tratar los campos en los que debería haber ceros y sí los hay. Para esto, al igual que antes, primero se muetran a ver qué columnas pueden poseer algún cero, y tal y como se aprecia los campos "eur_value" y "eur_wage" disponen de ceros. Con lo que para tratarlos se opta por emplear la misma técnica que para los nulos, por la misma razón.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Tratamiento de 0s
colSums(myDataAux == 0)
myDataAux$eur_value[myDataAux$eur_value==0] <- NA
myDataAux$eur_wage[myDataAux$eur_wage==0] <- NA
myDataAux$eur_value <- kNN(myDataAux)$eur_value
myDataAux$eur_wage <- kNN(myDataAux)$eur_wage
```

Por úlitmo, queda procesar los registros en los que hay valores vacíos. Con lo que en primer lugar, tal y como se ha estado haciendo hasta ahora, se listan todos los atributos observando si contienen valores vacios o no, se observa que la columna que hace referencia al equipo de cada jugador contiene valores vacíos, se da esta problemática cuando los jugadores están libres y actualmente no pertenecen a ningún equipo, con lo que se ha optado por sustituir el campo vacio por el valor de "Libre".

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Tratamiento de valores vacios
colSums(myDataAux == "")
myDataAux$club <- as.character(myDataAux$club)
myDataAux$club[myDataAux$eur_release_clause==""] <- "Libre"
myDataAux$club <- as.factor(myDataAux$club)
```

Como punto extra en este apartado, se ha considerado necesario tratar como Numeric los valores que el programa había recogido como Integers, debido a que son variables cuantitativas cuntinuas y han de tener este formato. Esto se realiza con el bucle que se aprecia a en el siguiente bloque, donde recorrerá cada una de las columnas comprobando el tipo de la misma y si detecta que es de tipo Integer será convertida a Numeric. Finalmente se muestra el tipo de cada uno de los atributos de este conjunto de datos junto con alguno de los registros que pueden llegar a tomar.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Transformación de integer a numerico
col.names = colnames(myDataAux)
for (i in 1:ncol(myDataAux)) {
  if (is.integer(myDataAux[,i])) {
    myDataAux[,i] <- as.numeric(myDataAux[,i])
  }
}

str(myDataAux)

```

## Identificación y tratamiento de valores extremos

En este apartado se detectarán los valores extremos que dispone en conjunto de datos en los campos de "overall", "eur_value", "eur_wage" y "eur_release_clause". Los valores extremos o __outliers__ son aquellos que se encuantran fuera de los esperados, ya sea porque son muy altos o muy bajos. A continuación se muestra un diagrama __boxplot__ para cada uno de los atributos.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario
par(mfrow = c(1,2))

boxplot(myDataAux$overall, main = "OVERALL")
overallAti <- boxplot.stats(myDataAux$overall)$out
summary(myDataAux$overall)
length(overallAti)

boxplot(myDataAux$eur_value, main = "EUR_VALUE")
eur_valueAti <- boxplot.stats(myDataAux$eur_value)$out
summary(myDataAux$eur_value)
length(eur_valueAti)

par(mfrow = c(1,2))
boxplot(myDataAux$eur_wage, main = "EUR_WAGE")
eur_wageAti <- boxplot.stats(myDataAux$eur_wage)$out
summary(myDataAux$eur_wage)
length(eur_wageAti)

boxplot(myDataAux$eur_release_clause, main = "EUR_RELEASE_CLAUSE")
eur_release_clauseAti <- boxplot.stats(myDataAux$eur_release_clause)$out
summary(myDataAux$eur_release_clause)
length(eur_release_clauseAti)

```
En primer lugar se analizarán los valores extremos para el atributo "overall". Esta columna consta de 142 __outliers__ y se corresponde con los jugadores que tienen una puntiación media superior a $84.5$ ($Q3+1.5\times IQR$) e inferior a $48.5$ ($Q1-1.5\times IQR$). En segundo lugar, se encuentra el atributo "eur_value", que por su parte tiene un mayor número de valores extremos, 2411, debido a las grandes diferencias que hay entre el coste de los jugadores. En este caso los valores extremos se encuentran cuando toman un valor superior a $4762500$ e inferior a $0$, con lo que no habrá ningun __outlier__ por abajo. En tercer lugar, se analizan los valores extremos del atributo "eur_wage", que consta de un total de 1899 valores, dándose cuando el salario del jugador es supeior a $30000$ e inferior a $0$, por lo que sucerederá lo mismo que para el atributo "eur_value" que no podía haber valores extremos por abajo. Por úlitmo, queda analizar los __outliers__ del atributo "eur_release_clause", que consta de 2460 valores extremos, apareciendo cuando la cláusula de rescisión del jugador es superior a $9000000$ e inferior a $0$, tal y como sucedía con los atributos anteriores.

# Análisis de los datos
## Selección de los grupos de datos a analizar

En este apartado se dividirán los registros del conjunto de datos en distintas agrupaciones en función de los valores que pueden llegar a tomar. 

La primera selección de grupos de datos será en función de la puntuación media que el juego otorga a cada jugador, separando así a los mejores jugadores ($overall \geq 80$), a los jugadores standard ($80 > overall \geq 65$) y a los peores jugadores ($overall < 65$).

La segunda segmentación se llevará a cabo en función de la edad de los jugadores, creando para este caso también tres rangos, el de los jugadores de mayor edad ($age \geq  31$), el de los jugadores de edad media ($31 > age \geq 21$) y el de los jugadores más jóvenes ($age < 21$).

En tercer lugar, se hará una selección de grupos en base a las cláusulas de rescisión de los jugadores, separando los que tiene cláusulas más altas ($eur\_release\_clause \geq 30000000$), cláusulas medias ($30000000>eur\_release\_clause \geq 5000000$) y cláusulas bajas ($eur_release_clause < 5000000$).

Por último, se hacen dos selecicones de grupos que son un tanto distintas al resto debido a que no emplean todo el conjunto de datos, y serán empleadas más adelante en la práctica. La primera de ellas diferencia a los jugadores en función de su nacionalidad, pero simplemente entre argentinos y brasileños. La segunda por su parte, es similar a la primera solo que la agrupación se realiza en base al club al que pertenece el jugador, seleccionando únicamente los jugadores del FC Barcelona y del Real Madrid CF.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
par(mfrow = c(2,2))
# Agrupación en función de la media de cada jugador
myDataAux.Mejores <- myDataAux[myDataAux$overall >= 80,]
myDataAux.Standars <- myDataAux[myDataAux$overall < 80 & myDataAux$overall >= 65,]
myDataAux.Peores <- myDataAux[myDataAux$overall < 65,]
#Representación gáfica
slices <- c(nrow(myDataAux.Mejores), nrow(myDataAux.Standars), nrow(myDataAux.Peores))
lbls <- c("Mejores Jugadores", "Jugadores Standard", "Peores Jugadores")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)), main="Puntuación media jugadores")

# Agrupación en funcion la edad de cada jugador
myDataAux.Veteranos <- myDataAux[myDataAux$age >= 31,]
myDataAux.Afincados <- myDataAux[myDataAux$age < 31 & myDataAux$age >= 21,]
myDataAux.Promesas <- myDataAux[myDataAux$age < 21,]
#Representación gáfica
slices <- c(nrow(myDataAux.Veteranos), nrow(myDataAux.Afincados), nrow(myDataAux.Promesas))
lbls <- c("Jugadores Veteranos", "Jugadores Afincados", "Jugadores Promesas")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)),main="Edad Jugadores")

#Agrupación en función de la clausula de rescisión de cada jugador
myDataAux.Alta <- myDataAux[myDataAux$eur_release_clause >= 30000000,]
myDataAux.Media <- myDataAux[myDataAux$eur_release_clause < 30000000 & myDataAux$eur_release_clause >= 5000000,]
myDataAux.Baja <- myDataAux[myDataAux$eur_release_clause < 5000000,]
#Representación gáfica
slices <- c(nrow(myDataAux.Alta), nrow(myDataAux.Media), nrow(myDataAux.Baja))
lbls <- c("Alta", "Media", "Baja")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)),main="Cláusula rescición jugadores")

# Agrupación en función de la nacionalidad
myDataAux.Argentinos <- myDataAux[myDataAux$nationality == "Argentina",]
myDataAux.Brasilenos <- myDataAux[myDataAux$nationality == "Brazil",]

#Agrupación en función del club
myDataAux.Barcelona <- myDataAux[myDataAux$club == "FC Barcelona",]
myDataAux.Madrid <- myDataAux[myDataAux$club == "Real Madrid CF",]

```

Tras realizar una representación gráfica de las agrupaciones que representan la puntuación media, la edad y la cláusula de rescisión de los jugadores se puede observar el porcentaje de jugadores que tiene cada uno de los grupos. Donde en las dos primeras agrupaciones de datos el mayor número de jugadores se encuentra en el rango medio, tal y como se podría esperar. No obstante, en la tercer agrupación, la de la cláusula de rescisión, el $80\%$ de los jugadores tiene lo que se ha considerado una cláusula de rescisión baja para lo que es la realidad.

## Comprobación de la normalidad y homogeneidad de la varianza

La normalidad ha de calcularse solo con las variables numéricas, con lo que en este caso podrá ser calculada con todos los atributos del conjunto de datos excepto con los atributos "name", "club" y "nationality". Dicho esto, porcedemos a calcular la normalidad empleando la técnica de Anderson-Darlinng, con la que habrá que comparar el p-valor obtenido por la aplicación de esta técnica con un porcentaje de significación del 5%, $\alpha=0,05$ , teniendo que ser el p-valor obtenido menor que $\alpha$ para que esta variable pueda ser considerada normal. Aunque existen diferentes test para determinar si un conjunto de datos sigue una distribución normal, se ha optado por el test comentado debido a que es el más adecuado cuando el dataset esta constituido por un gran número de instancias.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Normalidad
library(nortest)
alpha = 0.05
col.names = colnames(myDataAux)
for (i in 1:ncol(myDataAux)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.numeric(myDataAux[,i])) {
    p_val = ad.test(myDataAux[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i], "| con p-valor:", p_val,"\n")
    }
  }
}

```

Tras lograr el p-valor correspondiente de todas las variables numéricas, se puede determinar que ninguna de ellas sigue una distribución normal, puesto que sus p-valor son todos inferiores a $\alpha=0,05$.


La homogeneidad será calculada entre mútiples pares de atributos, el primero de ellos formado por los atributos que representan la puntuación media de cada jugador junto con el el valor económico que el juego otorga a cada jugador, y el segundo, por su parte, con los atributos que representan el salario y club de cada jugador. Para ello, se empleará el F-test, tal y como se aprecia a continuación:

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Homogeneidad
fligner.test(overall~eur_value, data = myDataAux)
fligner.test(eur_wage~club, data = myDataAux)

```

En el caso en el que se mide la homegeniedad entre la puntuación media y valor económico el p-valor obtenido es de $2.2e^{-16}$, siendo mucho menor que $0.05$, con lo que se considera que hay diferencias significativcas entre las varianzas de ambos grupos. Por otra parte, cuando la homegeneidad es medida entre el salario y el club de cada jugador, el p-valor resultante también es de $2.2e^{-16}$, por lo que como sucedía anteriormente si hay diferencias entre las varianzas de estos dos grupos.

## Aplicación de pruebas estadísticas
A continuación, se va a proceder a realizar un análisis estadístico, en el que se efecuarán: 

  * Contraste de hipótesis. 
  * Regreseión lineal Múltiple.
  * Regresión logística. 


### Contraste de hipótesis

En este estudio, se van a plantear dos contrastes de hipótesis.

**1)** Se pretende analizar, si los jugadores de nacionalidad argentina tienen mayor puntuación media (overall) que los brasileños. Para ello se emplearán los grupos de datos "myDataAux.Argentinos" y "myDataAux.Brasilenos" creados anteriormente. En esta ocasión, se procede a comparar estas dos nacionalidades por el interés que puede generar la rivalidad Argentina vs Brasileña, pero se podria realizar con diferentes nacionalidades de la misma manera, en lo que variará el resultado que se obtenga.

Para tener un conocimiento previo al contraste de hipótesis los datos de estas dos nacionalides, se muestra en el siguiente gráfico, la relación entre las diferentes puntuaciones de los jugadores de ambas nacionalidades:

```{r message= FALSE, warning=FALSE}
#Representación gáfica de las puntuaciones medias de argentinos y brasileños
library(ggplot2)
aux <- myDataAux[myDataAux$nationality=="Argentina" | myDataAux$nationality=="Brazil",]
aux$nationality <- as.character(aux$nationality)
aux$nationality <- as.factor(aux$nationality)
ggplot(data = aux[!is.na(aux[1:nrow(aux),]$overall),],aes(x=overall,fill=nationality))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")

```

Se procede con el contraste de hipótesis de dos muestras sobre la diferencia de medias: 

**Se establece la hipótesis nula y alternativa:**

Hipótesis nula:         $H_{0}: \mu_{1} - \mu_{2} = 0$

Hipótesis Alternativa:  $H_{1}: \mu_{1} - \mu_{2} < 0$

Como se observa, las hipótesis son unilaterales, donde $\mu_{1}$ representa la media de la población de la que se extráe la primera muestra (nacionalidad argentina), y $\mu_{2}$, por su parte, la media de la población de la segunda muestra (nacionalidad brasileña). La hipótesis nula, representa que los jugadores de nacionalidad argentina y brasileña, tienen una puntución media (overall) similar. En cambio, la hipótesis alternativa, representa, que los jugadores argentinos, tienen una puntuación inferior.

Se fija el valor de significación $\alpha=0.05$ y se procede a relizar el test, haciendo uso de la función **t.test** que facilita R.

**Se aplica el test**

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
t.test(myDataAux.Argentinos$overall, myDataAux.Brasilenos$overall, alternative = "less")
```

En base a los resultados, se rechaza la hipótesis nula, puesto que el p-valor obtenido es significativamente inferior a $\alpha=0.05$. Además, se aprecia que la puntuación media de los jugadores argentinos es de $67.72$ , mientras que los brasileños poseen una media de $70.86$ 

**2)** En el sigueinte contraste de hipótesis, se pretende analizar si los jugadores del F.C. Barcelona tienen salarios superiores que los jugadores del Real Madrid. En este caso se emplearán las agrupaciones de datos "myDataAux.Barcelona" y "myDataAux.Madrid" generadas en apartados anteriores. Al igual que sucedía en el apartado anterior, este analisis puede realizarse con diferentes clubes.

Antes de comenzar con el contraste de hipótesis, se procede a visualizar la relación de los salarios segun la puntuación de los jugadores y el club.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=52)}
#Representación gáfica de los salarios de cada equipo en función de la puntuación media de cada jugador

overallsBarc <- c(myDataAux.Barcelona$overall)
overallsMad <- c(myDataAux.Madrid$overall)

salarioBarc <- c(myDataAux.Barcelona$eur_wage)
salarioMad <- c(myDataAux.Madrid$eur_wage)

plot(overallsBarc, salarioBarc, type="overplotted", 
  pch=1, col="red", xlab="Overall",  
  ylab="eur_wage", 
  main="Salarios en función de la puntiación media")

lines(overallsMad,salarioMad,type="overplotted",pch=2,col="black")

legend("topleft",legend=c("FC Barcelona","Real Madrid CF"), pch=c(1,2),col=c("red","black"))

```

El planteamiento del contraste de hipótesis sigue el mismo formato que el anterior:

**Se define la hipótesis nula y alternativa:**

Hipótesis nula:         $H_{0}: \mu_{1} - \mu_{2} = 0$

Hipótesis Alternativa:  $H_{1}: \mu_{1} - \mu_{2} < 0$

En este caso, $\mu_{1}$ representa el salario de los jugadores del FC Barcelona y $\mu_{2}$ los salarios de los jugadores del Real Madrid CF, el contraste también es unilateral atendiendo a la formulación de la hipótesis, y se fija un nivel de confianza del $95\%$, es decir, un nivel de significación de $\alpha=0.05$.

**Se aplica el test**

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
t.test(myDataAux.Barcelona$eur_wage, myDataAux.Madrid$eur_wage, alternative = "less")

```

Con lo que tras haber llevado a cabo este contraste de hipótesis se acepta la hipótesis nula, debido a que el p-valor obtenido, $0,7521$ es mayor que $\alpha=0.05$.

### Regresión lineal

En este apartado, se procede a analizar la relación existente entre diferentes variables del conjunto de datos. Como se ha mencionado en el apartado de descripción de los datos, el conjunto tiene una gran antidad de variables, y por esta razón, para realizar la regresión lineal, se ha decidido utilizar las siguientes variables, según el criterio de los desarrolladores de la práctica, dado que, a modo de ver son variables que han de tener relación entre sí:

**Regresión Lineal Variable Overall**

Se va a estudiar el valor de la variable explicada ($Y = overal$) en función de:

  * Primer Modelo:
    * Variable explicada $Y = overall$.
    * variables explicativas $X = \left \{pac,sho,pas,dri,def,phy\right \}$.
  * Segundo Modelo:
    * Variable explicada $Y = overall$.
    * variables explicativas $X = \left \{pas,phy\right \}$. 
  * Tercer Modelo:
    * Variable explicada $Y = overall$.
    * variables explicativas $X = \left \{acceleration,finishing,sprint\_speed,stamina,long\_shots,vision,positioning\right \}$.

Para generar los distintos modelos, se hace uso de la función **lm** que proporciona R.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Creación de modelos de regresión lineal de overall

modelOverall_1 <- lm(overall ~ pac + sho + pas + dri + def + phy, data = myDataAux)
modelOverall_2 <- lm(overall ~ pas + phy, data = myDataAux)
modelOverall_3 <- lm(overall ~ acceleration + finishing + sprint_speed + stamina + long_shots + vision + positioning, data = myDataAux)

```

A continuación, se compara el resultado obtenido de los modelos, para escoger entre ellos, el que mejor resultado obtenga segun el coeficiente de determinacion "R2".

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Resultados de los modelos de regresión lineal de overall
resultados <- matrix(c(1, summary(modelOverall_1)$r.squared,
                       2, summary(modelOverall_2)$r.squared,
                       3, summary(modelOverall_3)$r.squared),
                     ncol = 2, byrow = TRUE)

colnames(resultados) <- c("Modelo", "R^2")

resultados

```

Como se aprecia en los resultados, el coeficiente de determinación (R2) que obtiene el mayor valor, corresponde al modelo de regresión:

  * Primer Modelo:
    * Variable explicada $Y = overall$.
    * variables explicativas $X = \left \{pac,sho,pas,dri,def,phy\right \}$.
  
A continuación, se observan los resultados de este modelo:
```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Resumen modelo1
summary(modelOverall_1)
```

Con los resultados del modelo se identifica lo siguiente:

  * Todos los coeficientes estimados son significativos.
  
  * Los coeficientes estimados, son significativos con un nivel de significancia del $0.1\%$ (’***’0.001)
  
  * El coeficiente de determinación R2 tiene un valor de: $0.7106$ y el ajustado de $0.7105$. Como se sabe que el valor de R2 está: $0 < R2 < 1$, cuanto mas cercano sea a 1, mayor es la proporción de variabilidad de la variable explicada ($Y$) por el modelo, y por tanto, mayor será la bondad del ajuste. En este caso, se puede comentar que el modelo de regresión múltiple generado explica el $71.06\%$ de la variabilidad de la variable overall de cada jugador. El valor de R2-ajustado es alto, y similar al de R2, lo que nos indica que el modelo tiene predictores útiles, aun así, cuanto mayor sea este valor mejor seria el modelo.

**Regresión Lineal Variable sho**

Se va a estudiar el valor de la variable explicada ($Y = sho$) en función de:

  * Primer Modelo:
    * Variable explicada $Y = sho$.
    * variables explicativas $X = \left \{finishing,heading\_accuracy,free\_kick\_accuracy,shot\_power,long\_shots,penalties\right \}$.
  * Segundo Modelo:
    * Variable explicada $Y = sho$.
    * variables explicativas $X = \left \{finishing,shot\_power\right \}$.
  * Tercer Modelo:
    * Variable explicada $Y = sho$.
    * variables explicativas $X = \left \{aggression,strength,interceptions\right \}$

Para generar los distintos modelos, se hace uso de la función **lm** que proporciona R.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Creación de modelos de regresión lineal de sho

modelShotting_1 <- lm(sho ~ finishing + heading_accuracy + free_kick_accuracy + shot_power + long_shots + penalties, data = myDataAux)
modelShotting_2 <- lm(sho ~ finishing + shot_power + long_shots, data = myDataAux)
modelShotting_3 <- lm(sho ~ aggression + strength + interceptions, data = myDataAux)

```

A continuación, se compara el resultado obtenido de los modelos, para escoger entre ellos, el que mejor resultado obtenga según el coeficiente de determinación "R2".

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Resultados de los modelos de regresión lineal de sho
resultados <- matrix(c(1, summary(modelShotting_1)$r.squared,
                       2, summary(modelShotting_2)$r.squared,
                       3, summary(modelShotting_3)$r.squared),
                     ncol = 2, byrow = TRUE)

colnames(resultados) <- c("Modelo", "R^2")

resultados
```

Como se observa en el resultado, el coeficiente de determinación (R2) que obtiene el mayor valor, corresponde al modelo de regresión:

  * Primer Modelo:
    * Variable explicada $Y = sho$.
    * variables explicativas $X = \left \{finishing,heading\_accuracy,free\_kick\_accuracy,\\shot\_power,long\_shots,penalties\right \}$.
  
A continuación, observamos los resultados de este modelo:

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Resumen modelo1
summary(modelShotting_1)
```

Con los resultados del modelo se identificar lo siguiente:

  * Todos los coeficientes estimados son significativos.
  
  * Los coeficientes estimados, son significativos con un nivel de significancia del $0.1\%$ (’***’0.001) y el coeficiente estimado de la variable penalties, tiene un nivel de significancia del $10\%$ (’.’0.1)
  
  * El coeficiente de determinación R2 tiene un valor de: $0.6065$ y el ajustado de $0.6064$. Como se sabe que el valor de R2 está: $0 < R2 < 1$, cuanto mas cercano sea a 1, mayor es la proporción de variabilidad de la variable explicada ($Y$) por el modelo, y por tanto, mayor será la bondad del ajuste. En este caso, se puede comentar que el modelo de regresión múltiple generado explica el $60.65\%$ de la variabilidad de la variable sho de cada jugador. El valor de R2-ajustado es superior a $0.5$ , y similar al de R2, lo que nos indica que el modelo tiene predictores útiles.

### Regresión logística

Para generar un modelo de regresión logística, se establece una variable dependiente binaria, es decir, que tome el valor $0$ o $1$ , en función del valor que pueda llegar a tener la propia variable. En el caso del dataset que se dispone, no nos econtramos con ninguna variable que nos permita realizar un estudio correcto a traves de una regresión logística. Por ello, para aplicar este tipo de regresión, basándonos en el valor de la varaible overall (puntuacion media del jugador), se va a generar una variable binaria que indique si un jugador es de calidad superior o inferior. Es decir, si la puntuacion media del jugador supera los 70 puntos, se esablece como que es un jugador de calidad "1", en cambio, si el jugador tiene una puntuación inferior a 70 se le asignará un "0".

Generamos la nueva varaible binaria y la introducimos en el dataset.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Generación de variable binaria
calidad <- ifelse(myDataAux$overall > 70,1,0)
myDataAux <- cbind(myDataAux,calidad)
myDataAux$calidad <- as.factor(myDataAux$calidad)
table(myDataAux$calidad)

```

Como se puede observar, se obtienen 13169 jugadores de baja calidad y 4825 de calidad alta. A continuación se procede con la generación de los modelos de regresión logística:

Como en el caso de la regresión lineal múltiple, se escogen diferentes variables explicativas con las que estudiar la variable explicada.

  * modelo1:
    * Variable Explicada $Y=calidad$.
    * Varaibles explicativas $X=\left \{pas,phy\right \}$.
  * modelo2:
    * Variable Explicada $Y=calidad$.
    * Varaibles explicativas $X=\left \{pas,phy,eur\_release\_clause\right \}$.
  * modelo3:
    * Variable Explicada $Y=calidad$.
    * Varaibles explicativas $X=\left \{pas,phy,eur\_release\_clause,club\right \}$.

Para generar los distintos modelos, se hace uso de la funcion **glm** que proporciona R, y se indica la "family" a la funcion, en este caso __binomial__.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Creación de modelos
modeloLog1 <- glm(calidad ~ pas + phy, data = myDataAux, family = "binomial")
modeloLog2 <- glm(calidad ~ pas + phy + eur_release_clause, data = myDataAux, family = "binomial")
modeloLog3 <- glm(calidad ~ pas + phy + eur_release_clause + club, data = myDataAux, family = "binomial")

resultados <- matrix(c(1, summary(modeloLog1)$aic,
                       2, summary(modeloLog2)$aic,
                       3, summary(modeloLog3)$aic),
                     ncol = 2, byrow = TRUE)
colnames(resultados) <- c("Modelo", "AIC")
```

A partir de los valores AIC obtenidos en los distintos modelos de regresión logística, se procede a seleccionar el que mejor resultados nos aporta, para a continuación, mostrar la curva roc correspondiente. Esta selección, se realiza en base al criterio del menor valor posible obtenido en el campo AIC.

Como se puede observar, el modelo2, que contiene las variables: Variable Explicada ($Y=calidad$) y varaibles explicativas $X=\left \{pas,phy,eur\_release\_clause\right \}$, es el que menor AIC, obtiene.

Por tanto, se visualiza la curva ROC correspondiente a este modelo y  su valor AUC (area under curve) correspondiente. Para ello, se obtienen las predicciones según el modelo generado, es decir, con el mejor de los modelos logísticos se calcularán las probabilidades de que un registro determinado pueda tomar el valor $0$ (puntuación media baja) o $1$ (puntuación media alta):


```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Obtenemos las predicciones
predicciones <- predict(modeloLog2, type = "response")
library(pROC)
# Se introducen los resultados de las probabilidades en una nueva columna del dataset.
myDataAux$prob = predicciones
# Se genera la curva Roc
g <- roc(calidad ~ prob, data = myDataAux)
# Visualizar la curva
plot(g)
# Funcion que ofrece el area bajo la curva
auc(g)
```

A través de la curva ROC, se evalúa la bondad de ajuste del modelo generado. Cada punto de la curva corresponde a un nivel de umbral de discriminación en la matriz de confusión. Es decir, se construyen todas las matrices desde un umbral del $1\%$ al $99\%$.

Observando la gráfica que se ha obtenido, y teniendo en cuenta el valor AUC (__Area under the curve__), $0.9837$, obtenido gracias al modelo generado, se puede deducir que la bondad de este es casi "perfecta", es decir, que dispone de una bondad alta. Por tanto, el modelo en cuestión es bastante bueno cuando se pretende conocer si un jugador es o no de calidad, haciendo uso de los datos $\left \{pas,phy,eur\_release\_clause\right \}$.

A continuación, se realiza una prueba de predicción empleando el modelo que ha ofrecido mejores resultados:
```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Predicción
newData1 <- data.frame(pas = 79,phy=50,eur_release_clause=1000000)
#pred2 <- predict(modeloLog2,newData1,type = "response")
newData2 <- data.frame(pas = 80,phy=80,eur_release_clause=15000000)
#pred1 <- predict(modeloLog2,newData2,type = "response")


resultados <- matrix(c(1, predict(modeloLog2,newData1,type = "response"),
                       2, predict(modeloLog2,newData2,type = "response")),
                     ncol = 2, byrow = TRUE)
colnames(resultados) <- c("Num prueba", "Probabilidad de calidad alta")
resultados
```
Se han realizado dos predicciones, una primera en la cual los valores otorgados a las variables explicativas son relativamente bajos, y una segunda en la que estas variables toman valores más elevados. Con lo que tras generar estos datos de test, se considera que el primer caso tiene un $2\%$ de probabilidades de que se trate de un jugador de calidad, mientras que el segundo se puede garantizar con casi toda seguridad de que será un jugador de calidad alta, debido a que ha obtenido un $99\%$ de probabilidades de serlo.


# Conclusiones
Tras realizar esta práctica, se han llevado a cabo diferentes pruebas estadísticas con el conjunto de datos "Fifa 18 More Complete Player Dataset", ya mencionado. Realizando análisis de las variables más intuitivas por las que está compuesto este dataset, con la intención de cumplir todos los objetivos propuestos en la actividad práctica.

Apoyándonos en la visualización de gráficos y tablas los resultados se han podido interpretar de forma más sencilla, debido a que los resultados que llegan a ofrecer ciertas herramientas pueden resultar un tanto confusos.

Mediante los contrastes de hipótesis sobre dos muestras realizados se ha conseguido determinar la diferencia que estas muestras tienen entre sí en base a unos atributos determinados. En este caso, se han analizado por un lado el nivel de los jugadores en función de su nacionalidad, y por otro lado, la diferencia de salarios en base al club al que pertence cada jugador.

La regresión lineal, ha permitido conocer qué atributos del conjunto de datos guardan mayor relación con las variables objetivo, de esta forma dando valor a estos atributos se podría llegar a conocer la variación en la variable estudiada en cuestión. En este caso se han estudiado dos variables, la puntución media del jugador y la puntuación media de disparo del jugador.

Como último análisis estadístico, se ha propuesto una regresión logística la cual permite conocer según ciertas características si un jugador es considerado de calidad alta o baja. Mediante los modelos conseguidos con esta regresión pueden llegar a realizarse predicciones, donde otorgando un valor a los atributos explicativos puede obtenerse una estimación de si este jugador es de calidad baja o alta.

Previos a estos análisis, ha sido necesario preprocesar el conjunto de datos. En primer lugar se ha realizado una eliminación de atributos que se consideraban innecesarios para el estudio. Posteriormente, se han tratado los registros que disponían de ceros, valores vacíos o valores nulos en alguno de sus atributos. Además, también se han estudiado los valores extremos de las principales columnas del conjunto de datos. Por último, se han realizado grupos de datos en función de los valores que toman determindos atributos.


```{r message= FALSE, warning=FALSE}
#Comentario

```
