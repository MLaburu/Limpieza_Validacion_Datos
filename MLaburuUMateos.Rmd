---
title: 'Pr?ctica 2: Limpieza y validaci?n de los datos'
author: "Autores: Mikel Laburu Haro, Unai Mateos Corral"
date: "Curso 2018/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: paper
    toc: yes
    toc_depth: 3
    includes:
      in_header: Cabecera.html
lang: es
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

******
# Introducción
## Descripción

En esta actividad se lleva a cabo el tratamiento del dataset "Fifa 18 More Complete Player Dataset" extraido de Kaggle (https://www.kaggle.com/kevinmh/fifa-18-more-complete-player-dataset/home), con el que se elabora un caso pr?ctico en el que se emplean herramientas de integraci?n, limpieza, validaci?n y an?lisis.

## Objetivos
Los objetivos que se pretenden lograr mediante la elaboraci?n de esta actividad son los siguientes:
\begin{itemize}
\item Aprender a aplicar los conocimientos adquiridos y su capacidad de resoluci?n de problemas en entornos nuevos o poco conocidos dentro de contextos m?s amplios o multidisciplinares.
\item Saber identificar los datos relevantes y los tratamientos necesarios (integraci?n, limpieza y validaci?n) para llevar a cabo un proyecto anal?tico.
\item Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
\item Identificar la mejor representaci?n de los resultados para aportar conclusiones sobre el problema planteado en el proceso anal?tico.
\item Actuar con los principios ?ticos y legales relacionados con la manipulaci?n de datos en función del ámbito de aplicación.
\item Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
\item Desarrollar la capacidad de búsqueda, gesti?n y uso de informaci?n y recursos en el ?mbito de la ciencia de datos.
\end{itemize}

## Competencias
Desarrollando a su vez las siguientes competencias del máster de Ciencia de Datos:
\begin{itemize}
\item Capacidad de analizar un problema en el nivel de abstraccn adecuado a cada situaci?n y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
\item Capacidad para aplicar las t?cnicas espec?ficas de tratamiento de datos (integraci?n, transformaci?n, limpieza y validaci?n) para su posterior an?lisis.
\end{itemize}
******
# Dataset

# Descripci?n del dataset

A continuaci?n se realiza la carga del conjuto de datos al completo, y posteriormente se hace la selecci?n de los atributos que se consideran de mayor relevancia, llegando a simplificar el datataset considerablemente, reduciendo el n?mero de columnas de 185 a 46. Adem?s, a modo de ejemplo, se muestra el valor de cinco atributos de las diez primeras instancias.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Cargamos el Dataset
myData <- read.csv("FIFA.csv", header = TRUE, sep = ",")
# Seleccion de los atributos a utilizar
myDataAux <- myData[,c("name","club","age","height_cm","weight_kg","nationality","eur_value", "eur_wage", "eur_release_clause",
                       "overall","potential","pac","sho","pas","dri","def","phy","crossing","finishing","heading_accuracy", "short_passing",
                       "volleys","dribbling","curve","free_kick_accuracy","long_passing","ball_control","acceleration","sprint_speed",
                       "agility", "reactions", "balance", "shot_power", "jumping", "stamina", "strength", "long_shots", "aggression",
                       "interceptions","positioning","vision","penalties","composure","marking","standing_tackle","sliding_tackle")]

# Mostrar las primeras 10 lineas del dataset y el contenido de 5 variables
head(myDataAux[,1:5],10)
# Tipo de los datos de cada variable
sapply(myDataAux,class)
```
Este conjunto de datos consta de un total de 17994 registros de jugadores, y como ya se ha comentado, cada una de ellos queda finalmente caracterizado por 46 atributos, entre los que se puede observar su nombre, su salarioo sus habilidades. A continuaci?n se realiza una breve descripci?n de alguno de estos atributos:
\begin{itemize}
\item \textbf{Name}: Nombre completo del jugador.
\item \textbf{Club}: Equipo al que pertenece el jugador.
\item \textbf{Age}: Edad del jugador.
\item \textbf{Eur_value}: Valor en euros que el juego estima para el jugador.
\item \textbf{Eur_wage}: Salario en euros del jugador.
\item \textbf{Eur_release_clause}: Cl?usula de rescisi?n del jugador.
\item \textbf{Overall}: Puntuaci?n media del jugador.
\item \textbf{PAC}: (Ritmo) Atributo que representa la media de los atributos de veloricadad (aceleraci?n, velocidad...).
\item \textbf{Sho}: (Disparo) Atributo que representa la media de los atributos de disparo (finalizaci?n, remate de cabeza...).
\item \textbf{Pas}: (Pase) Atributo que representa la media de los atributos de pase (pase en corto, pase en largo...).
\item \textbf{Dri}: (Regate) Atributo que representa la media de los atributos de regate (control del bal?n, dribring...).
\item \textbf{Def}: (Defensa) Atributo que representa la media de los atributos defensivos (anticipaci?n, entrada...).
\item \textbf{Phy}: (F?sico) Atributo que representa la media de los atributos f?sicos (resistencia, fuerza...).
\end{itemize}


# Limpieza de los datos
## Eliminaci?n de ceros, vacios y nulos
En este apartado se pretende limpiar el conjunto de datos de tal forma que no disponga ni de ceros, ni de valores vac?os, ni de valores nulos.

En primer lugar se realizar? el tratamiento de valores nulos, como se aprecia a continuaci?n el conjunto de datos dispone de valores nulos en los campos de la columna "eur_release_clause". Para no disponer de estos valores existen distintas estrategias como eliminar los registros en los que aparece este valor o asignar la media de "eur_release_clause" a estos campos, pero en este caso se ha considerado m?s oportuno la imputaci?n de valores basada en $k$ vecinos m?s pr?ximos, o m?s com?nmente conocida como $kNN-imputation$, debido principalmente a que los registros de este conjunto de datos guardan relaci?n entre s?.
```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
library(VIM)

colSums(is.na(myDataAux))

# Tratamiento de valores nulos
myDataAux$eur_release_clause <- kNN(myDataAux)$eur_release_clause

```

Tras comprobar que no quedan valores nulos, es momento de tratar los campos en los que deber?a haber ceros y s? los hay. Para esto, al igual que antes, primero se muetran a ver qu? columnas pueden poseer alg?n cero, y tal y como se aprecia los campos "eur_value" y "eur_wage" disponen de ceros. Con lo que para tratarlos se opta por emplear la misma t?cnica que para los nulos, por la misma raz?n.

```{r message= FALSE, warning=FALSE}
#Tratamiento de 0s
colSums(myDataAux == 0)
myDataAux$eur_value[myDataAux$eur_value==0] <- NA
myDataAux$eur_wage[myDataAux$eur_wage==0] <- NA
myDataAux$eur_value <- kNN(myDataAux)$eur_value
myDataAux$eur_wage <- kNN(myDataAux)$eur_wage
```

Por ?litmo, 

```{r message= FALSE, warning=FALSE}
# Tratamiento de valores vacios
colSums(myDataAux == "")
myDataAux$club <- as.character(myDataAux$club)
myDataAux$club[myDataAux$eur_release_clause==""] <- "Libre"
myDataAux$club <- as.factor(myDataAux$club)
```

```{r message= FALSE, warning=FALSE}
# Transformaci?n de integer a numerico
col.names = colnames(myDataAux)
for (i in 1:ncol(myDataAux)) {
  if (is.integer(myDataAux[,i])) {
    myDataAux[,i] <- as.numeric(myDataAux[,i])
  }
}

str(myDataAux)

```
## Identificaci?n y tratamiento de valores extremos

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario
par(mfrow = c(1,2))

boxplot(myDataAux$overall, main = "OVERALL")
overallAti <- boxplot.stats(myDataAux$overall)$out
length(overallAti)

boxplot(myDataAux$eur_value, main = "EUR_VALUE")
eur_valueAti <- boxplot.stats(myDataAux$eur_value)$out
length(eur_valueAti)

par(mfrow = c(1,2))
boxplot(myDataAux$eur_wage, main = "EUR_WAGE")
eur_wageAti <- boxplot.stats(myDataAux$eur_wage)$out
length(eur_wageAti)

boxplot(myDataAux$eur_release_clause, main = "EUR_RELEASE_CLAUSE")
eur_release_clauseAti <- boxplot.stats(myDataAux$eur_release_clause)$out
length(eur_release_clauseAti)

```

# An?lisis de los datos
## Selecci?n de los grupos de datos a analizar

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
par(mfrow = c(2,2))
# Agrupaci?n en funci?n de la media de cada jugador
myDataAux.Mejores <- myDataAux[myDataAux$overall >= 80,]
myDataAux.Standars <- myDataAux[myDataAux$overall < 80 & myDataAux$overall >= 65,]
myDataAux.Peores <- myDataAux[myDataAux$overall < 65,]
#Representaci?n g?fica
slices <- c(nrow(myDataAux.Mejores), nrow(myDataAux.Standars), nrow(myDataAux.Peores))
lbls <- c("Mejores Jugadores", "Jugadores Standard", "Peores Jugadores")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)), main="Puntuaci?n media jugadores")

# Agrupaci?n en funcion la edad de cada jugador
myDataAux.Veteranos <- myDataAux[myDataAux$age >= 31,]
myDataAux.Afincados <- myDataAux[myDataAux$age < 31 & myDataAux$age >= 21,]
myDataAux.Promesas <- myDataAux[myDataAux$age < 21,]
#Representaci?n g?fica
slices <- c(nrow(myDataAux.Veteranos), nrow(myDataAux.Afincados), nrow(myDataAux.Promesas))
lbls <- c("Jugadores Veteranos", "Jugadores Afincados", "Jugadores Promesas")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)),main="Edad Jugadores")

#Agrupaci?n en funci?n de la clausula de rescisi?n de cada jugador
myDataAux.Alta <- myDataAux[myDataAux$eur_release_clause >= 30000000,]
myDataAux.Media <- myDataAux[myDataAux$eur_release_clause < 30000000 & myDataAux$eur_release_clause >= 5000000,]
myDataAux.Baja <- myDataAux[myDataAux$eur_release_clause < 5000000,]
#Representaci?n g?fica
slices <- c(nrow(myDataAux.Alta), nrow(myDataAux.Media), nrow(myDataAux.Baja))
lbls <- c("Alta", "Media", "Baja")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)),main="Cl?usula rescici?n jugadores")

# Agrupaci?n en funci?n de la nacionalidad
myDataAux.Argentinos <- myDataAux[myDataAux$nationality == "Argentina",]
myDataAux.Brasilenos <- myDataAux[myDataAux$nationality == "Brazil",]

#Agrupaci?n en funci?n del club
myDataAux.Barcelona <- myDataAux[myDataAux$club == "FC Barcelona",]
myDataAux.Madrid <- myDataAux[myDataAux$club == "Real Madrid CF",]

```

## Comprobaci?n de la normalidad y homogeneidad de la varianza

La normalidad ha de calcularse solo con las variables num?ricas, teniendo en nuestro caso simplemente el campo "Purchase", puesto que aunque el resto de variables tambi?n lo puedan paracer se tratan de variables discretas cuyos valores representan una categor?a o estado.Dicho esto, porcedemos a calcular la normalidad empleando la t?cnica de Anderson-Darlinng, con la que habr? que comparar el p-valor obtenido por la aplicaci?n de esta t?cnica con un porcentaje de significaci?n del 5%, $\alpha=0,05$ , teniendo que ser el p-valor obtenido menor que $\alpha$ para que esta variable sea normal. Aunque existen diferentes test para determinar si un conjunto de datos sigue una distribuci?n normal, se ha optado por el test comentado debido a que es el m?s adecuado cuando el dataset esta constituido por un gran n?mero de instancias.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Normalidad
library(nortest)
alpha = 0.05
col.names = colnames(myDataAux)
for (i in 1:ncol(myDataAux)) {
  if (i == 1) cat("Variables que no siguen una distribuci?n normal:\n")
  if (is.numeric(myDataAux[,i])) {
    p_val = ad.test(myDataAux[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i], "| con p-valor:", p_val,"\n")
    }
  }
}

```

Tras lograr el p-valor correspondiente a la variable no categ?rica "Purchase", se puede determinar que no sigue una distribuci?n normal, puesto que su p-valor es inferior a $\alpha=0,05$ .


La homogeneidad ser? calculada entre m?tiples pares de atributos, el primero de ellos formado por los atributos que representan el gasto realizado junto con el estado civil de cada persona, y el segundo, por su parte, con los atributos que representan el gasto de cada persona junto con su g?nero. Para ello, se emplear? el F-test, tal y como se aprecia a continuaci?n:

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
# Homogeneidad
fligner.test(overall~eur_value, data = myDataAux)
fligner.test(eur_wage~club, data = myDataAux)

```

En el caso en el que se mide la homegeniedad entre el gasto y el estado civil el p-valor obtenido es de 0.2897, siendo mucho mayor que 0.05, con lo que se considera que no hay diferencias significativcas entre las varianzas de ambos grupos. No obstante, cuando la homegeneidad es medida entre el gasto de cada persona junto con su g?nero, el p-valor resultante es de 2.2e-16, siendo considerablemente inferior a 0.05, por lo que si hay diferencias entre las varianzas de estos dos grupos.

## Aplicación de pruebas estadísticas

A continuación, se va a proceder a realizar un análisis estadístico, en el que se efecuarán: 

  * Contraste de hipótesis. 
  * Regreseión lineal Múltiple.
  * Regresión logística. 

### Contraste de hipotesis

En este estudio, se van a plantear dos contrastes de hipotesis.

**1)** Se pretende analizar, si los jugadores de nacionalidad _argentina_ tienen mayor puntuación media (overall) que los _brasileños_. Para ello se emplearan los grupos de datos "myDataAux.Argentinos" y "myDataAux.Brasilenos" creados anteriormente. En esta ocasion, se procede a comparar estas dos nacionalidades por el interes que puede generar la rivalidad Argentina vs Brasileña, pero se podria realizar con diferentes nacionalidades de la misma manera, en lo que variara el resultado que se obtenga.

Para conocer un poco previo al contraste de hipotesis los datos de estas dos nacionalides, se muestra en el siguiente grafico, la relacion entre las diferentes puntuaciones de los jugadores de ambas nacionalidades:

```{r message= FALSE, warning=FALSE}
#Representación gráfica de las puntuaciones medias de argentinos y brasileños
library(ggplot2)
aux <- myDataAux[myDataAux$nationality=="Argentina" | myDataAux$nationality=="Brazil",]
aux$nationality <- as.character(aux$nationality)
aux$nationality <- as.factor(aux$nationality)
ggplot(data = aux[!is.na(aux[1:nrow(aux),]$overall),],aes(x=overall,fill=nationality))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```


Se procede con el contraste de hipótesis de dos muestras sobre la diferencia de medias: 

**Se establecen la hipótesis nula y alternativa:**

Hipotesis nula:         $H_{0}: \mu_{1} - \mu_{2} = 0$

Hipotesis Alternativa:  $H_{1}: \mu_{1} - \mu_{2} < 0$

Como se observa, las hipotesis son unilaterales, donde $\mu_{1}$ representa la media de la población de la que se extráe la primera muestra (nacionalidad argentina), y $\mu_{2}$, por su parte, la media de la población de la segunda muestra (nacionalidad brasileña). La hipotesis nula, representa que los jugadores de nacionalidad argentina y brasileña, tienen una puntucion media (overall) similar. En cambio, la hipotesis alternativa, representa, que los jugadores argentinos, tienen una puntuacion inferior.

Se fija el valor de significación $\alpha=0.05$ y se procede a relizar el test, haciendo uso de la funcion **t.test** que facilita R.

**Se aplica el test**

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
t.test(myDataAux.Argentinos$overall, myDataAux.Brasilenos$overall, alternative = "less")
```

En base a los resultados, se rechaza la hipótesis nula, puesto que el p-valor obtenido es significativamente inferior a $\alpha=0.05$. Además, se aprecia que la puntuación media de los jugadores argentinos es de $67.72$ , mientras que los brasileños poseen una media de $70.86$ 

**2)** En el sigueinte contraste de hipótesis, se pretende analizar si los jugadores del F.C. Barcelona tienen salarios superiores que los jugadores del Real Madrid. En este caso se emplearán las agrupaciones de datos "myDataAux.Barcelona" y "myDataAux.Madrid" generadas en apartados anteriores. Como en el apartado anterior, este analisis puede realizarse con diferentes clubes.

Antes de comenzar con el contraste de hipótesis, se procede a visualizar la relacion de los salarios segun la puntuacion de los jugadores y el club.

```{r message= FALSE, warning=FALSE}
#Representaci?n g?fica de los salarios de cada equipo en función de la puntuación media de cada jugador

overallsBarc <- c(myDataAux.Barcelona$overall)
overallsMad <- c(myDataAux.Madrid$overall)

salarioBarc <- c(myDataAux.Barcelona$eur_wage)
salarioMad <- c(myDataAux.Madrid$eur_wage)

plot(overallsBarc, salarioBarc, type="overplotted", 
  pch=1, col="red", xlab="Overall",  
  ylab="eur_wage", 
  main="Salarios en función de la puntiación media")

lines(overallsMad,salarioMad,type="overplotted",pch=2,col="black")

legend("topleft",legend=c("FC Barcelona","Real Madrid CF"), pch=c(1,2),col=c("red","black"))

```

El planteamiento del contraste de hipótesis sigue el mismo formato que el anterior:

**Se establecen la hipótesis nula y alternativa:**

Hipotesis nula:         $H_{0}: \mu_{1} - \mu_{2} = 0$

Hipotesis Alternativa:  $H_{1}: \mu_{1} - \mu_{2} < 0$

En este caso, $\mu_{1}$ representa el salario de los jugadores del F.C. Barcelona y $\mu_{2}$ los salarios de los jugadores del Real Madrid, el contraste también es unilateral atendiendo a la formulación de la hipótesis, y se fija un nivel de confianza del $95\%$, es decir, un nivel de significación de $\alpha=0.05$.

**Se aplica el test**

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
t.test(myDataAux.Barcelona$eur_wage, myDataAux.Madrid$eur_wage, alternative = "less")
```

Con lo que tras haber llevado a cabo este contraste de hipótesis se acepta la hipótesis nula, debido a que el p-valor obtenido, $0,7521$ es mayor que $\alpha=0.05$.

### Regresión lineal

En este apartado, se procede a analizar la relacion existente entre diferentes variables del conjunto de datos. Como se ha mencionado en el apartado de descripcion de los datos, el conjunto tiene una granc antidad de variables, y por esta razon, para realizar la regresion lineal, se ha decidido utilizar las siguientes variables, segun el criterio de los desarrolladores de la práctica, dado que, a modo de ver son variables que han de tener relacion entre si:

**Regresión Lineal Variable Overall**

Se va a estudiar el valor de la variable explicada (Y = overal) en funcion de:

* Primer Modelo:    variables explicativas X = {pac,sho,pas,dri,def,phy} 
* Segundo Modelo:   variables explicativas X = {pas,phy} 
* Tercer Modelo:    variables explicativas X = {acceleration,finishing,sprint_speed,stamina,long_shots,vision,positioning} 

Para generar los distintos modelos, se hace uso de la funcion **lm** que proporciona R.
```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario

modelOverall_1 <- lm(overall ~ pac + sho + pas + dri + def + phy, data = myDataAux)
modelOverall_2 <- lm(overall ~ pas + phy, data = myDataAux)
modelOverall_3 <- lm(overall ~ acceleration + finishing + sprint_speed + stamina + long_shots + vision + positioning, data = myDataAux)
```

A continuación, se compara el resultado obtenido de los modelos, para escoger entre ellos, el que mejor resultado obtenga segun el coeficiente de determinacion "R2".

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario
resultados <- matrix(c(1, summary(modelOverall_1)$r.squared,
                       2, summary(modelOverall_2)$r.squared,
                       3, summary(modelOverall_3)$r.squared),
                     ncol = 2, byrow = TRUE)

colnames(resultados) <- c("Modelo", "R^2")

resultados
```

Como se observa en el resultado, el coeficiente de determinacion (R2) que obtiene el mayor valor, corresponde al modelo de regresión:

  * Primer Modelo:    variables explicativas X = {pac,sho,pas,dri,def,phy}
  
Acontinuación, observamos los resultados de este modelo:
```{r message= FALSE, warning=FALSE}
#Resumen modelo1
summary(modelOverall_1)
```

Con los resultados del modelo se identificar lo siguiente:

  * Todos los coeficientes estimados son significativos.
  
  * Los coeficientes estimados, son significativos con un nivel de significancia del 0.1% (’***’0.001)
  
  * El coeficiente de determinación R2 tiene un valor de: 0.7106 y el ajustado de 0.7105 Como se sabe que el valor de R2 esta: 0 < R2 < 1, cuanto mas cercano sea a 1, mayor es la proporción de variabilidad de la variable explicada (Y) por el modelo, y por tanto, mayor será la bondad del ajuste. En este caso, se puede comentar que el modelo de regresión múltiple generado explica el 71.06% de la variabilidad de la variable overall de cada jugador. El valor de R2-ajustado es alto, y similar al de R2, lo que nos indica que el modelo tiene predictores útiles, aun asi, cuanto mayor sea este valor mejor seria el modelo.

**Regresión Lineal Variable sho**

Se va a estudiar el valor de la variable explicada (Y = sho) en funcion de:

* Primer Modelo:    variables explicativas X = {finishing,heading_accuracy,free_kick_accuracy,shot_power,long_shots,penalties} 
* Segundo Modelo:   variables explicativas X = {finishing,shot_power} 
* Tercer Modelo:    variables explicativas X = {aggression,strength,interceptions} 

Para generar los distintos modelos, se hace uso de la funcion **lm** que proporciona R.

```{r message= FALSE, warning=FALSE}
#Generamos los modelos
modelShotting_1 <- lm(sho ~ finishing + heading_accuracy + free_kick_accuracy + shot_power + long_shots + penalties, data = myDataAux)
modelShotting_2 <- lm(sho ~ finishing + shot_power + long_shots, data = myDataAux)
modelShotting_3 <- lm(sho ~ aggression + strength + interceptions, data = myDataAux)
```

A continuación, se compara el resultado obtenido de los modelos, para escoger entre ellos, el que mejor resultado obtenga segun el coeficiente de determinacion "R2".

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario
resultados <- matrix(c(1, summary(modelShotting_1)$r.squared,
                       2, summary(modelShotting_2)$r.squared,
                       3, summary(modelShotting_3)$r.squared),
                     ncol = 2, byrow = TRUE)

colnames(resultados) <- c("Modelo", "R^2")

resultados
```

Como se observa en el resultado, el coeficiente de determinacion (R2) que obtiene el mayor valor, corresponde al modelo de regresión:

  * Primer Modelo:    variables explicativas X = {finishing,heading_accuracy,free_kick_accuracy,shot_power,long_shots,penalties} 
  
Acontinuación, observamos los resultados de este modelo:

```{r message= FALSE, warning=FALSE}
#Resumen modelo1
summary(modelShotting_1)
```

Con los resultados del modelo se identificar lo siguiente:

  * Todos los coeficientes estimados son significativos.
  
  * Los coeficientes estimados, son significativos con un nivel de significancia del 0.1% (’***’0.001) y el coeficiente estimado de la variable penalties, tiene un nivel de significancia del 10% (’.’0.1)
  
  * El coeficiente de determinación R2 tiene un valor de: 0.6065 y el ajustado de 0.6064 Como se sabe que el valor de R2 esta: 0 < R2 < 1, cuanto mas cercano sea a 1, mayor es la proporción de variabilidad de la variable explicada (Y) por el modelo, y por tanto, mayor será la bondad del ajuste. En este caso, se puede comentar que el modelo de regresión múltiple generado explica el 60.65% de la variabilidad de la variable sho de cada jugador. El valor de R2-ajustado es superior a 0.5 , y similar al de R2, lo que nos indica que el modelo tiene predictores útiles.

### Regresión logística

Para generar un modelo de regresion logistica, se establece una variable dependiente binaria, es decir, que tome un valor $0$ o $1$ , dependiendo de la variable. En el caso del dataset que disponemos, no nos econtramos con una variable que nos permita realizar un estudio correcto a traves de una regresion logistica. Por ello, para aplicar este tipo de regresion, basandonos en el valor de la varaible overall (puntuacion media del jugador), se va a generar una variable binaria que indique si un jugador es de calidad superior o inferior. Es decir, si la puntuacion media del jugador supera el valor 70, se esablece como que es un jugador de calidad "1", en cambio, si el jugador tiene una puntuacion inferior un "0".

Generamos la nueva varaible vinaria y la introducimos en el dataset.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Comentario
calidad <- ifelse(myDataAux$overall > 70,1,0)
myDataAux <- cbind(myDataAux,calidad)
myDataAux$calidad <- as.factor(myDataAux$calidad)
table(myDataAux$calidad)

```

Como se puede observar, se obtienen 13169 jugadores de baja calidad y 4825 de calidad alta. A continuacion se procede con la generacion de los modelos de regresion logistica:

Como en el caso de la regresion lineal multiple, se escogen diferentes variables explicativas con las que estudiar la variable explicada.

  * modelo1: Variable Explicada (Y=calidad) y varaibles explicativas X={pas,phy}
  * modelo2: Variable Explicada (Y=calidad) y varaibles explicativas X={pas,phy,eur_release_clause}
  * modelo3: Variable Explicada (Y=calidad) y varaibles explicativas X={pas,phy,eur_release_clause,club}

Para generar los distintos modelos, se hace uso de la funcion **glm** que proporciona R, y se indica la "family" a la funcion, en este caso binomial.

```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
modeloLog1 <- glm(calidad ~ pas + phy, data = myDataAux, family = "binomial")
modeloLog2 <- glm(calidad ~ pas + phy + eur_release_clause, data = myDataAux, family = "binomial")
modeloLog3 <- glm(calidad ~ pas + phy + eur_release_clause + club, data = myDataAux, family = "binomial")

resultados <- matrix(c(1, summary(modeloLog1)$aic,
                       2, summary(modeloLog2)$aic,
                       3, summary(modeloLog3)$aic),
                     ncol = 2, byrow = TRUE)
colnames(resultados) <- c("Modelo", "AIC")

resultados
```

A partir de los valores AIC obtenidos en los distintos modelos de regresión logística, se procede a seleccionar el que mejor resultados nos aporta, para a continuacion, mostrar la curva roc correspondiente. Esta seleccion, se realiza en base al criterio de selección del menor valor posible obtenido en el campo AIC.

Como se puede observar, el modelo2, que contiene las variables: Variable Explicada (Y=calidad) y varaibles explicativas X={pas,phy,eur_release_clause}, es el que menor AIC, obtiene.

Por tanto, se visualiza la curva ROC correspondiente a este modelo y  su valor AUC (area under curve) correspondiente. Para ello, se obtienen las predicciones segun el modelo generado, es decir, con el mejor de los modelos logísticos se calcularán las probabilidades de que un registro determinado pueda tomar el valor $0$ (puntuación media baja) o $1$ (puntuación media alta):


```{r message= FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=55)}
#Obtenemos las predicciones
predicciones <- predict(modeloLog2, type = "response")
library(pROC)
# Se introducen los resultados de las probabilidades en una nueva columna del dataset.
myDataAux$prob = predicciones
# Se genera la curva Roc
g <- roc(calidad ~ prob, data = myDataAux)
# Visualizar la curva
plot(g)
# Funcion que ofrece el area bajo la curva
auc(g)
```

A través de la curva ROC, se evalúa la bondad de ajuste en la regresión logística obtenida. Cada punto de la curva corresponde a un nivel de umbral de discriminación en la matriz de confusión. Es decir, se construyen todas las matrices desde un umbral del 1% al 99%.

Observando la grafica que se ha obtenido, y teniendo en cuenta el valor AUC de la curva con el modelo generado, se puede deducir que la bondad del modelo es casi "perfecta", es decir, que el modelo dispone de una bondad alta. Por tanto, el modelo generado para conocer si un jugador es o no de calidad, haciendo uso de los datos {pas,phy,eur_release_clause} es bastante bueno.
